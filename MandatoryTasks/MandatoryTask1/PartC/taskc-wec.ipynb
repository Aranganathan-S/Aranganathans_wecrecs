{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code\n!pip install transformers datasets accelerate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T04:58:54.913485Z","iopub.execute_input":"2025-10-22T04:58:54.913704Z","iopub.status.idle":"2025-10-22T05:00:05.830604Z","shell.execute_reply.started":"2025-10-22T04:58:54.913681Z","shell.execute_reply":"2025-10-22T05:00:05.829888Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**old code for whole dataset**","metadata":{}},{"cell_type":"markdown","source":"****new code for new dataset****","metadata":{}},{"cell_type":"markdown","source":"We are using 10% original training dataset for training the model and the other 10& of the training dataset for validation during training. The validation dataset in the original source is used for computing final f1 score","metadata":{}},{"cell_type":"code","source":"import transformers\nimport datasets\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n\nprint(f\"Transformers version: {transformers.__version__}\")\nprint(f\"Datasets version: {datasets.__version__}\")\n\n\nMODEL_CHECKPOINT = \"distilbert-base-uncased\"\nBATCH_SIZE = 16\nMAX_LENGTH = 384\nDOC_STRIDE = 128\n\ntry:\n    raw_datasets = load_dataset(\"lucadiliello/newsqa\")\nexcept Exception as e:\n    print(f\"Failed to load 'newsqa' dataset. Error: {e}\")\n    print(\"Please ensure you have internet access enabled in your Kaggle notebook.\")\n\nprint(\"\\n--- Original Datasets ---\")\nprint(raw_datasets)\n\n\nfinal_evaluation_dataset = raw_datasets[\"validation\"]\nprint(f\"\\nSaved final evaluation set with {len(final_evaluation_dataset)} rows.\")\n\nshuffled_train = raw_datasets[\"train\"].shuffle(seed=42)\ntrain_size_10_percent = int(len(shuffled_train) * 0.1)\nnew_train_split = shuffled_train.select(range(train_size_10_percent))\nnew_valid_split = shuffled_train.select(range(train_size_10_percent, train_size_10_percent * 2))\nraw_datasets[\"train\"] = new_train_split\nraw_datasets[\"validation\"] = new_valid_split\n\nprint(\"\\n--- Resampled Datasets for Training/Validation ---\")\nprint(raw_datasets)\nprint(\"\\n--- New Training Sample ---\")\nprint(raw_datasets[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T05:03:21.637702Z","iopub.execute_input":"2025-10-22T05:03:21.638435Z","iopub.status.idle":"2025-10-22T05:03:25.840815Z","shell.execute_reply.started":"2025-10-22T05:03:21.638406Z","shell.execute_reply":"2025-10-22T05:03:25.839978Z"}},"outputs":[{"name":"stdout","text":"Transformers version: 4.53.3\nDatasets version: 4.1.1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/681 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"756eb983223948158b20b0eccffd8b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-ec54fbe500fc3b(…):   0%|          | 0.00/29.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f24941c7fa04362b29c16e629a5942c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-3cf888b12(…):   0%|          | 0.00/1.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4192d3abaa643ab8ba772ebae42128f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31808f934e144fd2a17eb06e8d92942f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb161419d134dce8565d26567b84743"}},"metadata":{}},{"name":"stdout","text":"\n--- Original Datasets ---\nDatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answers', 'key', 'labels'],\n        num_rows: 74160\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answers', 'key', 'labels'],\n        num_rows: 4212\n    })\n})\n\nSaved final evaluation set with 4212 rows.\n\n--- Resampled Datasets for Training/Validation ---\nDatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answers', 'key', 'labels'],\n        num_rows: 7416\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answers', 'key', 'labels'],\n        num_rows: 7416\n    })\n})\n\n--- New Training Sample ---\n{'context': 'NEW DELHI, India (CNN) -- More than a dozen trucks loaded with fruits, spices and other goods Tuesday crossed the line dividing Kashmir as India and Pakistan opened a symbolic trade route in the disputed region for the first time in more than 60 years.\\n\\n\\n\\nKashmiris watch as Indian trucks cross into the border town of Chakothi in Pakistani-administered Kashmir.\\n\\n\\n\\nTo cheers and band music, the first trucks rumbled from the Pakistani side across a white bridge to a brightly decorated trade center festooned . Apple-laden Indian trucks heading the other way were also warmly welcomed.\\n\\n\\n\\nIt is hoped the move will ease tensions in the troubled Himalayan region, which has been a conflict flashpoint between nuclear-armed neighbors India and Pakistan who both lay claims to the territory.\\n\\n\\n\\n\"Today, we have regained our lost market,\" said Ghulam Rasool Bhat, president of the Kashmir fruit growers\\' association.  Watch more about the historic day »\\n\\n\\n\\n\"We are sending the sweet Kashmir apple as the first consignment. This is sure to sweeten the relation between the two neighbors. The beginning of the trade between the two Kashmirs will further improve the relations and lead to a peaceful resolution of the bitter problem,\" he said.\\n\\n\\n\\nThe trucks were subjected to thorough security checks before they crossed the bridge, one of the few crossing points in the heavily militarized 742-kilometer (460-mile) Line of Control, the de facto frontier that divides the region.\\n\\n\\n\\nKashmir has been a major source of dispute between India, and Pakistan since the two countries were partitioned at the end of British rule in 1947. Muslim Kashmiris sided with Pakistan to the north, while the Hindu south joined India.\\n\\n\\n\\nFor the past 18 years, Kashmir has been wracked by a bloody separatist campaign. Authorities say up to 43,000 people have died, but rights groups and non-governmental organizations put the death toll at twice that.\\n\\n\\n\\nViolence had dropped off since the countries began a peace process in 2004, but it surged after the state government in Indian-controlled Kashmir announced plans in June to donate land for a Hindu shrine.\\n\\n\\n\\nMuslim protests following the decision prompted a government U-turn that triggered Hindu demonstrations calling for it to be restored. Subsequent violence left 40 dead and hundreds wounded.\\n\\n\\n\\nIt is hoped Tuesday\\'s route opening will bolster the peace agreement and combat lingering mistrust between India and Pakistan. A bilateral cease-fire has been holding in the region for more than four years.\\n\\n\\n\\nA bus service connecting the divided Kashmir began amid much fanfare in 2005 but struggled under the weight of elaborate security checks and stifling bureaucracy.\\n\\n\\n\\n\"This is a great emotional moment, as it brings to mind my grandfather, who used to drive lorries on this road,\" said Muzhar Hussain Naqvi, who drove the leading Pakistani truck.\\n\\n\\n\\nCNN\\'s Sara Sidner and Mukhtar Ahmad contributed to this report', 'question': 'What is a source of a bitter dispute?', 'answers': ['Kashmir'], 'key': '177636272dad4ac7addecc3ef7fc296c', 'labels': [{'end': [1483], 'start': [1477]}]}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n\nif not tokenizer.is_fast:\n    raise ValueError(\n        \"This script requires a fast tokenizer for 'return_offsets_mapping'.\"\n        \"Please use a different model checkpoint.\"\n    )\n    \npad_on_right = tokenizer.padding_side == \"right\"\n\ndef prepare_train_features(examples):\n    \"\"\"\n    Preprocesses the training data.\n    - Tokenizes question + context pairs.\n    - Handles long contexts with striding.\n    - Maps character answer spans to token spans.\n    \"\"\"\n    examples[\"question\"] = [q.strip() for q in examples[\"question\"]]\n\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=MAX_LENGTH,\n        stride=DOC_STRIDE,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        labels = examples[\"labels\"][sample_index]\n    \n        if not labels or not labels[0]['start']:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n            continue\n        start_char = labels[0]['start'][0]\n        end_char = labels[0]['end'][0]\n        token_start_index = 0\n        while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n            token_start_index += 1\n\n        token_end_index = len(input_ids) - 1\n        while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n            token_end_index -= 1\n\n\n        if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n    \n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n           \n            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                token_start_index += 1\n            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n\n    \n            while offsets[token_end_index][1] >= end_char:\n                token_end_index -= 1\n            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples\n\ntokenized_datasets = raw_datasets.map(\n    prepare_train_features,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n    num_proc=2  \n)\n\nprint(\"\\n--- Tokenized Training Data Sample ---\")\nprint(tokenized_datasets[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T05:06:58.595647Z","iopub.execute_input":"2025-10-22T05:06:58.596372Z","iopub.status.idle":"2025-10-22T05:07:29.508623Z","shell.execute_reply.started":"2025-10-22T05:06:58.596341Z","shell.execute_reply":"2025-10-22T05:07:29.507680Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb62b825a96446ca81c81cc1e2c5cefd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba838d558164b87b2cb606551527f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ef95e4c555440596249c28499541bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc49a37bba384da986d20e3834e63df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/7416 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4438ab9026dc458881a0da0a52e87800"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/7416 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189e3381eb934fb083d124b8082ecb92"}},"metadata":{}},{"name":"stdout","text":"\n--- Tokenized Training Data Sample ---\n{'input_ids': [101, 2054, 2003, 1037, 3120, 1997, 1037, 8618, 7593, 1029, 102, 2047, 6768, 1010, 2634, 1006, 13229, 1007, 1011, 1011, 2062, 2084, 1037, 6474, 9322, 8209, 2007, 10962, 1010, 21729, 1998, 2060, 5350, 9857, 4625, 1996, 2240, 16023, 13329, 2004, 2634, 1998, 4501, 2441, 1037, 12613, 3119, 2799, 1999, 1996, 11621, 2555, 2005, 1996, 2034, 2051, 1999, 2062, 2084, 3438, 2086, 1012, 13329, 2483, 3422, 2004, 2796, 9322, 2892, 2046, 1996, 3675, 2237, 1997, 15775, 23342, 4048, 1999, 9889, 1011, 8564, 13329, 1012, 2000, 21250, 1998, 2316, 2189, 1010, 1996, 2034, 9322, 22257, 2013, 1996, 9889, 2217, 2408, 1037, 2317, 2958, 2000, 1037, 14224, 7429, 3119, 2415, 17037, 7828, 2098, 1012, 6207, 1011, 14887, 2796, 9322, 5825, 1996, 2060, 2126, 2020, 2036, 22775, 10979, 1012, 2009, 2003, 5113, 1996, 2693, 2097, 7496, 13136, 1999, 1996, 11587, 28333, 2555, 1010, 2029, 2038, 2042, 1037, 4736, 5956, 8400, 2090, 4517, 1011, 4273, 10638, 2634, 1998, 4501, 2040, 2119, 3913, 4447, 2000, 1996, 3700, 1012, 1000, 2651, 1010, 2057, 2031, 11842, 2256, 2439, 3006, 1010, 1000, 2056, 1043, 21886, 3286, 20710, 13669, 1038, 12707, 1010, 2343, 1997, 1996, 13329, 5909, 4982, 2545, 1005, 2523, 1012, 3422, 2062, 2055, 1996, 3181, 2154, 1090, 1000, 2057, 2024, 6016, 1996, 4086, 13329, 6207, 2004, 1996, 2034, 9530, 5332, 16206, 3672, 1012, 2023, 2003, 2469, 2000, 4086, 2368, 1996, 7189, 2090, 1996, 2048, 10638, 1012, 1996, 2927, 1997, 1996, 3119, 2090, 1996, 2048, 13329, 2015, 2097, 2582, 5335, 1996, 4262, 1998, 2599, 2000, 1037, 9379, 5813, 1997, 1996, 8618, 3291, 1010, 1000, 2002, 2056, 1012, 1996, 9322, 2020, 13532, 2000, 16030, 3036, 14148, 2077, 2027, 4625, 1996, 2958, 1010, 2028, 1997, 1996, 2261, 5153, 2685, 1999, 1996, 4600, 23689, 6590, 18425, 6356, 2475, 1011, 20595, 1006, 17267, 1011, 3542, 1007, 2240, 1997, 2491, 1010, 1996, 2139, 13743, 8880, 2008, 20487, 1996, 2555, 1012, 13329, 2038, 2042, 1037, 2350, 3120, 1997, 7593, 2090, 2634, 1010, 1998, 4501, 2144, 1996, 2048, 3032, 2020, 13571, 2098, 2012, 1996, 2203, 1997, 2329, 3627, 1999, 4006, 1012, 5152, 13329, 2483, 11536, 2007, 4501, 2000, 1996, 2167, 1010, 2096, 1996, 7560, 2148, 2587, 2634, 1012, 2005, 1996, 2627, 2324, 2086, 1010, 13329, 2038, 2042, 23277, 8684, 2098, 2011, 1037, 6703, 19802, 25879, 2923, 3049, 1012, 4614, 2360, 2039, 2000, 4724, 1010, 2199, 2111, 2031, 2351, 1010, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'start_positions': 306, 'end_positions': 306}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nfrom transformers import EarlyStoppingCallback\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(MODEL_CHECKPOINT)\n\nargs = TrainingArguments(\n    output_dir=\"finetuned-newsqa\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\", \n    learning_rate=2e-5,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=False,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=default_data_collator,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T05:07:29.510257Z","iopub.execute_input":"2025-10-22T05:07:29.510974Z","iopub.status.idle":"2025-10-22T05:07:31.949543Z","shell.execute_reply.started":"2025-10-22T05:07:29.510941Z","shell.execute_reply":"2025-10-22T05:07:31.948712Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f07b8d54a64b60907134b84711bbe1"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_37/1954319160.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(MODEL_CHECKPOINT)\n\nargs = TrainingArguments(\n    output_dir=\"finetuned-newsqa\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    num_train_epochs=10, \n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=False,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"loss\",  \n    greater_is_better=False,      \n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=default_data_collator,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T05:20:23.945993Z","iopub.execute_input":"2025-10-22T05:20:23.946329Z","iopub.status.idle":"2025-10-22T05:20:24.315593Z","shell.execute_reply.started":"2025-10-22T05:20:23.946302Z","shell.execute_reply":"2025-10-22T05:20:24.314951Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_37/3715813353.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nprint(\"--- Starting Training ---\")\ntrain_result = trainer.train()\nprint(\"--- Training Finished ---\")\n\ntrainer.save_model()  \ntrain_metrics = train_result.metrics\ntrainer.log_metrics(\"train\", train_metrics)\ntrainer.save_metrics(\"train\", train_metrics)\ntrainer.save_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T05:20:26.620077Z","iopub.execute_input":"2025-10-22T05:20:26.620573Z","iopub.status.idle":"2025-10-22T05:51:21.744957Z","shell.execute_reply.started":"2025-10-22T05:20:26.620546Z","shell.execute_reply":"2025-10-22T05:51:21.744163Z"}},"outputs":[{"name":"stdout","text":"--- Starting Training ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4660' max='11650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 4660/11650 30:53 < 46:21, 2.51 it/s, Epoch 4/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.856200</td>\n      <td>1.644364</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.308300</td>\n      <td>1.356617</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.959800</td>\n      <td>1.406179</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.660500</td>\n      <td>1.507911</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"--- Training Finished ---\n***** train metrics *****\n  epoch                    =        4.0\n  total_flos               =  6801070GF\n  train_loss               =     1.2659\n  train_runtime            = 0:30:54.12\n  train_samples_per_second =    100.484\n  train_steps_per_second   =      6.283\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T06:01:26.949812Z","iopub.execute_input":"2025-10-22T06:01:26.950095Z","iopub.status.idle":"2025-10-22T06:01:30.745863Z","shell.execute_reply.started":"2025-10-22T06:01:26.950075Z","shell.execute_reply":"2025-10-22T06:01:30.744888Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport collections\nfrom tqdm.auto import tqdm\nimport evaluate \n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n    all_start_logits, all_end_logits = raw_predictions\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"key\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"key\"]]].append(i)\n\n    predictions = collections.OrderedDict()\n    print(f\"Post-processing {len(examples)} examples split into {len(features)} features.\")\n\n    for example_index, example in enumerate(tqdm(examples)):\n        feature_indices = features_per_example[example_index]\n        min_null_score = None\n        valid_answers = []\n        context = example[\"context\"]\n        \n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            \n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                        or end_index < start_index\n                        or start_index == cls_index\n                        or end_index == cls_index\n                        or (end_index - start_index + 1) > max_answer_length\n                    ):\n                        continue\n                    \n                \n                    if not (features[feature_index][\"sequence_ids\"][start_index] == (1 if pad_on_right else 0) and\n                            features[feature_index][\"sequence_ids\"][end_index] == (1 if pad_on_right else 0)):\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    \n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char:end_char],\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        predictions[example[\"key\"]] = best_answer[\"text\"]\n\n    return predictions\n\n\n\nprint(\"\\n--- Running Predictions on FINAL VALIDATION SET ---\")\n\n-\ndef prepare_validation_features(examples):\n    examples[\"question\"] = [q.strip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=MAX_LENGTH,\n        stride=DOC_STRIDE,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    tokenized_examples[\"key\"] = []\n    tokenized_examples[\"sequence_ids\"] = [] \n    \n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"key\"].append(examples[\"key\"][sample_index])\n\n        # Get the sequence ids\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        tokenized_examples[\"sequence_ids\"].append(sequence_ids)\n        \n        # Set offset_mapping to None for question tokens\n        offset_mapping = tokenized_examples[\"offset_mapping\"][i]\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == (1 if pad_on_right else 0) else None)\n            for k, o in enumerate(offset_mapping)\n        ]\n    return tokenized_examples\n\nvalidation_features = final_evaluation_dataset.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=final_evaluation_dataset.column_names,\n    num_proc=2\n)\n\nfinal_raw_predictions = trainer.predict(validation_features)\n\nfinal_predictions = postprocess_qa_predictions(\n    final_evaluation_dataset,\n    validation_features,\n    final_raw_predictions.predictions\n)\n\n\nmetric = evaluate.load(\"squad\")\n\nformatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n\nformatted_references = []\nfor ex in final_evaluation_dataset:\n    formatted_references.append({\n        \"id\": ex[\"key\"],\n        \"answers\": {\n            \"text\": ex[\"answers\"],\n            \"answer_start\": [l['start'][0] for l in ex['labels'] if l['start']]\n        }\n    })\n\nresults = metric.compute(predictions=formatted_predictions, references=formatted_references)\n\nprint(\"\\n--- FINAL Evaluation Results (on full validation set) ---\")\nprint(f\"Exact Match (EM): {results['exact_match']:.2f}%\")\nprint(f\"F1 Score: {results['f1']:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T06:51:06.184370Z","iopub.execute_input":"2025-10-22T06:51:06.184655Z","iopub.status.idle":"2025-10-22T07:24:31.786878Z","shell.execute_reply.started":"2025-10-22T06:51:06.184630Z","shell.execute_reply":"2025-10-22T07:24:31.786290Z"}},"outputs":[{"name":"stdout","text":"\n--- Running Predictions on FINAL VALIDATION SET ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Post-processing 4212 examples split into 10567 features.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4212 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40545450002d4c03bda4991ddcb792ad"}},"metadata":{}},{"name":"stdout","text":"\n--- FINAL Evaluation Results (on full validation set) ---\nExact Match (EM): 34.40%\nF1 Score: 48.17%\n","output_type":"stream"}],"execution_count":15}]}